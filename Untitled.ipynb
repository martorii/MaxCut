{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weight matrix\n",
    "n = 3\n",
    "min_weight = -1\n",
    "max_weight = 1\n",
    "W = np.random.uniform(low=min_weight, high=max_weight, size=(n,n))\n",
    "i_lower = np.tril_indices(n, -1)\n",
    "W[i_lower] = W.T[i_lower]\n",
    "np.fill_diagonal(W, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.31497974 -0.821219  ]\n",
      " [ 0.31497974  0.          0.21884597]\n",
      " [-0.821219    0.21884597  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "m = gp.Model(\"max-cut\")\n",
    "k = 2\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "x = m.addVars(n, vtype=GRB.BINARY, name='partitions')\n",
    "z = m.addVars(n, n, vtype=GRB.BINARY, name=\"edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (0, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (1, 2): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 0): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 1): <gurobi.Constr *Awaiting Model Update*>,\n",
       " (2, 2): <gurobi.Constr *Awaiting Model Update*>}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.addConstrs((z[i,j]<=x[i]+x[j] for i in range(n) for j in range(n)), \"1\")\n",
    "m.addConstrs((z[i,j]+x[i]+x[j]<=2 for i in range(n) for j in range(n)), \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_f = gp.quicksum(W[(i,j)]*z[(i,j)] for i in range(n) for j in range(n))\n",
    "m.setObjective(obj_f, GRB.MAXIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.0.1 build v9.0.1rc0 (win64)\n",
      "Optimize a model with 18 rows, 12 columns and 48 nonzeros\n",
      "Model fingerprint: 0x13026489\n",
      "Variable types: 0 continuous, 12 integer (12 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [2e-01, 8e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [2e+00, 2e+00]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 14 rows and 8 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 4 rows, 4 columns, 12 nonzeros\n",
      "Found heuristic solution: objective 1.0676514\n",
      "Variable types: 0 continuous, 4 integer (4 binary)\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 1.06765 -0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.067651429506e+00, best bound 1.067651429506e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximize\n",
      "   <gurobi.QuadExpr: 0.0 + [ weights[0,0] * edges[0,0] + weights[0,1] * edges[0,1] + weights[0,2] * edges[0,2] + weights[1,0] * edges[1,0] + weights[1,1] * edges[1,1] + weights[1,2] * edges[1,2] + weights[2,0] * edges[2,0] + weights[2,1] * edges[2,1] + weights[2,2] * edges[2,2] ]>\n",
      "Subject To\n",
      "Binaries\n",
      "   ['partitions[0]', 'partitions[1]', 'partitions[2]', 'edges[0,0]', 'edges[0,1]', 'edges[0,2]', 'edges[1,0]', 'edges[1,1]', 'edges[1,2]', 'edges[2,0]', 'edges[2,1]', 'edges[2,2]']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (m.display())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0676514295060389"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.getObjective().getValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<gurobi.Var partitions[0] (value 1.0)>,\n",
       " <gurobi.Var partitions[1] (value -0.0)>,\n",
       " <gurobi.Var partitions[2] (value 1.0)>,\n",
       " <gurobi.Var edges[0,0] (value 0.0)>,\n",
       " <gurobi.Var edges[0,1] (value 1.0)>,\n",
       " <gurobi.Var edges[0,2] (value 0.0)>,\n",
       " <gurobi.Var edges[1,0] (value 1.0)>,\n",
       " <gurobi.Var edges[1,1] (value 0.0)>,\n",
       " <gurobi.Var edges[1,2] (value 1.0)>,\n",
       " <gurobi.Var edges[2,0] (value 0.0)>,\n",
       " <gurobi.Var edges[2,1] (value 1.0)>,\n",
       " <gurobi.Var edges[2,2] (value 0.0)>]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.getVars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, -0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "nodes = m.getVars()\n",
    "best_partition = []\n",
    "for i in range(n):\n",
    "    best_partition.append(nodes[i].x)\n",
    "print(best_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "code_folding": [
     23,
     119,
     180,
     195,
     200,
     212,
     244,
     265,
     271,
     277,
     283,
     292,
     301,
     329,
     1259,
     1304
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  0 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  0 , ratio( WF ): 1.0000000000000002\n",
      "Iter  1 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  1 , ratio( RPF ): 0.9231854814552962\n",
      "Iter  1 , ratio( WF ): 1.0\n",
      "Iter  2 , ratio( GBF ): 0.9825790666414469\n",
      "Iter  2 , ratio( RPF ): 0.968954151560542\n",
      "Iter  2 , ratio( WF ): 1.0000000000000002\n",
      "Iter  3 , ratio( GBF ): 0.9673492503610374\n",
      "Iter  3 , ratio( RPF ): 0.9673492503610371\n",
      "Iter  3 , ratio( WF ): 0.8826484626934246\n",
      "Iter  4 , ratio( GBF ): 1.0000000000000004\n",
      "Iter  4 , ratio( RPF ): 0.9145477051873993\n",
      "Iter  4 , ratio( WF ): 0.9351343844751774\n",
      "Iter  5 , ratio( GBF ): 1.0\n",
      "Iter  5 , ratio( RPF ): 0.891438524569349\n",
      "Iter  5 , ratio( WF ): 0.9999999999999999\n",
      "Iter  6 , ratio( GBF ): 1.0\n",
      "Iter  6 , ratio( RPF ): 0.9824606332157558\n",
      "Iter  6 , ratio( WF ): 0.982460633215756\n",
      "Iter  7 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  7 , ratio( RPF ): 0.9252170714020959\n",
      "Iter  7 , ratio( WF ): 0.863131721130116\n",
      "Iter  8 , ratio( GBF ): 0.9548052593164761\n",
      "Iter  8 , ratio( RPF ): 0.8639752877641563\n",
      "Iter  8 , ratio( WF ): 0.8883003716388077\n",
      "Iter  9 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  9 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  9 , ratio( WF ): 0.9466132154987338\n",
      "Iter  10 , ratio( GBF ): 0.9861173016264565\n",
      "Iter  10 , ratio( RPF ): 0.9634201270678467\n",
      "Iter  10 , ratio( WF ): 0.9591226198461389\n",
      "Iter  11 , ratio( GBF ): 1.0000000000000004\n",
      "Iter  11 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  11 , ratio( WF ): 0.9410141583450424\n",
      "Iter  12 , ratio( GBF ): 0.9999999999999997\n",
      "Iter  12 , ratio( RPF ): 0.985086327854476\n",
      "Iter  12 , ratio( WF ): 0.9448445040028611\n",
      "Iter  13 , ratio( GBF ): 0.9959553811238916\n",
      "Iter  13 , ratio( RPF ): 0.997006924066777\n",
      "Iter  13 , ratio( WF ): 0.9970069240667769\n",
      "Iter  14 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  14 , ratio( RPF ): 1.0\n",
      "Iter  14 , ratio( WF ): 1.0000000000000002\n",
      "Iter  15 , ratio( GBF ): 0.9999999999999996\n",
      "Iter  15 , ratio( RPF ): 0.871749811789183\n",
      "Iter  15 , ratio( WF ): 0.9197825293891618\n",
      "Iter  16 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  16 , ratio( RPF ): 0.940209787791289\n",
      "Iter  16 , ratio( WF ): 0.9710792896702877\n",
      "Iter  17 , ratio( GBF ): 0.9617495291597907\n",
      "Iter  17 , ratio( RPF ): 0.9268106824804756\n",
      "Iter  17 , ratio( WF ): 0.9268106824804755\n",
      "Iter  18 , ratio( GBF ): 1.0\n",
      "Iter  18 , ratio( RPF ): 0.9174533997032711\n",
      "Iter  18 , ratio( WF ): 0.8507958762865967\n",
      "Iter  19 , ratio( GBF ): 0.9890577497038935\n",
      "Iter  19 , ratio( RPF ): 0.9595261450342882\n",
      "Iter  19 , ratio( WF ): 0.9890577497038937\n",
      "Iter  20 , ratio( GBF ): 1.0\n",
      "Iter  20 , ratio( RPF ): 0.941638806644229\n",
      "Iter  20 , ratio( WF ): 0.9999999999999999\n",
      "Iter  21 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  21 , ratio( RPF ): 0.9524634291985564\n",
      "Iter  21 , ratio( WF ): 0.8556145628252635\n",
      "Iter  22 , ratio( GBF ): 1.0000000000000004\n",
      "Iter  22 , ratio( RPF ): 0.9959835091482329\n",
      "Iter  22 , ratio( WF ): 0.9925034309104117\n",
      "Iter  23 , ratio( GBF ): 0.9870293904429617\n",
      "Iter  23 , ratio( RPF ): 0.9502561641139117\n",
      "Iter  23 , ratio( WF ): 0.9746475113794834\n",
      "Iter  24 , ratio( GBF ): 0.9999999999999999\n",
      "Iter  24 , ratio( RPF ): 0.9812145081948656\n",
      "Iter  24 , ratio( WF ): 0.9554784612362143\n",
      "Iter  25 , ratio( GBF ): 0.9906450941513788\n",
      "Iter  25 , ratio( RPF ): 0.9519649632954481\n",
      "Iter  25 , ratio( WF ): 0.9737653827419396\n",
      "Iter  26 , ratio( GBF ): 0.9717447073080926\n",
      "Iter  26 , ratio( RPF ): 0.9522364796827354\n",
      "Iter  26 , ratio( WF ): 0.924002840270491\n",
      "Iter  27 , ratio( GBF ): 1.0000000000000004\n",
      "Iter  27 , ratio( RPF ): 0.9299329000709396\n",
      "Iter  27 , ratio( WF ): 1.0000000000000004\n",
      "Iter  28 , ratio( GBF ): 0.9999999999999997\n",
      "Iter  28 , ratio( RPF ): 0.912959258498592\n",
      "Iter  28 , ratio( WF ): 0.9129592584985924\n",
      "Iter  29 , ratio( GBF ): 0.9999999999999998\n",
      "Iter  29 , ratio( RPF ): 0.9409698744215155\n",
      "Iter  29 , ratio( WF ): 0.8908984235229747\n",
      "Iter  30 , ratio( GBF ): 0.9739628787552017\n",
      "Iter  30 , ratio( RPF ): 0.9999999999999996\n",
      "Iter  30 , ratio( WF ): 0.9465395599145321\n",
      "Iter  31 , ratio( GBF ): 1.0000000000000004\n",
      "Iter  31 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  31 , ratio( WF ): 1.0000000000000002\n",
      "Iter  32 , ratio( GBF ): 0.9877461967571295\n",
      "Iter  32 , ratio( RPF ): 0.9877461967571296\n",
      "Iter  32 , ratio( WF ): 0.9393746102452617\n",
      "Iter  33 , ratio( GBF ): 1.0\n",
      "Iter  33 , ratio( RPF ): 0.9697034039264482\n",
      "Iter  33 , ratio( WF ): 0.9797640013226654\n",
      "Iter  34 , ratio( GBF ): 0.9999999999999998\n",
      "Iter  34 , ratio( RPF ): 0.9765439702524485\n",
      "Iter  34 , ratio( WF ): 0.9765439702524488\n",
      "Iter  35 , ratio( GBF ): 1.0\n",
      "Iter  35 , ratio( RPF ): 0.973799307186645\n",
      "Iter  35 , ratio( WF ): 1.0\n",
      "Iter  36 , ratio( GBF ): 0.9872457732659469\n",
      "Iter  36 , ratio( RPF ): 0.9999999999999999\n",
      "Iter  36 , ratio( WF ): 0.9999999999999997\n",
      "Iter  37 , ratio( GBF ): 0.9874094534783111\n",
      "Iter  37 , ratio( RPF ): 1.0\n",
      "Iter  37 , ratio( WF ): 0.9874094534783111\n",
      "Iter  38 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  38 , ratio( RPF ): 0.9621053573938462\n",
      "Iter  38 , ratio( WF ): 0.9216134938168368\n",
      "Iter  39 , ratio( GBF ): 0.9667364255112079\n",
      "Iter  39 , ratio( RPF ): 0.917711070030848\n",
      "Iter  39 , ratio( WF ): 0.8923964387886312\n",
      "Iter  40 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  40 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  40 , ratio( WF ): 0.9325317443202142\n",
      "Iter  41 , ratio( GBF ): 0.98867363989728\n",
      "Iter  41 , ratio( RPF ): 0.98867363989728\n",
      "Iter  41 , ratio( WF ): 0.98867363989728\n",
      "Iter  42 , ratio( GBF ): 0.9999999999999999\n",
      "Iter  42 , ratio( RPF ): 0.9417728081071564\n",
      "Iter  42 , ratio( WF ): 0.9999430852176572\n",
      "Iter  43 , ratio( GBF ): 1.0\n",
      "Iter  43 , ratio( RPF ): 0.9927828100071422\n",
      "Iter  43 , ratio( WF ): 0.9254540073446329\n",
      "Iter  44 , ratio( GBF ): 0.9910233310565526\n",
      "Iter  44 , ratio( RPF ): 0.9576380638492015\n",
      "Iter  44 , ratio( WF ): 0.9878093570201532\n",
      "Iter  45 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  45 , ratio( RPF ): 0.9352825644925837\n",
      "Iter  45 , ratio( WF ): 0.9352825644925841\n",
      "Iter  46 , ratio( GBF ): 0.9994301833689001\n",
      "Iter  46 , ratio( RPF ): 0.9359887406357222\n",
      "Iter  46 , ratio( WF ): 0.9359887406357223\n",
      "Iter  47 , ratio( GBF ): 1.0\n",
      "Iter  47 , ratio( RPF ): 0.9032085312332191\n",
      "Iter  47 , ratio( WF ): 0.9695431437548963\n",
      "Iter  48 , ratio( GBF ): 1.0\n",
      "Iter  48 , ratio( RPF ): 0.923462278049238\n",
      "Iter  48 , ratio( WF ): 1.0\n",
      "Iter  49 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  49 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  49 , ratio( WF ): 1.0000000000000004\n",
      "Iter  50 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  50 , ratio( RPF ): 0.9399691127806123\n",
      "Iter  50 , ratio( WF ): 0.9399691127806122\n",
      "Iter  51 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  51 , ratio( RPF ): 0.9740976971859665\n",
      "Iter  51 , ratio( WF ): 0.9746635954300255\n",
      "Iter  52 , ratio( GBF ): 0.983565710513116\n",
      "Iter  52 , ratio( RPF ): 0.983565710513116\n",
      "Iter  52 , ratio( WF ): 0.983565710513116\n",
      "Iter  53 , ratio( GBF ): 0.9554298224234155\n",
      "Iter  53 , ratio( RPF ): 0.8993451770656579\n",
      "Iter  53 , ratio( WF ): 1.0\n",
      "Iter  54 , ratio( GBF ): 0.9999999999999999\n",
      "Iter  54 , ratio( RPF ): 0.9999999999999999\n",
      "Iter  54 , ratio( WF ): 0.9351242400051997\n",
      "Iter  55 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  55 , ratio( RPF ): 0.9894730223758931\n",
      "Iter  55 , ratio( WF ): 0.9894730223758933\n",
      "Iter  56 , ratio( GBF ): 0.9999999999999994\n",
      "Iter  56 , ratio( RPF ): 0.9999999999999997\n",
      "Iter  56 , ratio( WF ): 0.9999999999999999\n",
      "Iter  57 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  57 , ratio( RPF ): 0.978904697381939\n",
      "Iter  57 , ratio( WF ): 0.978904697381939\n",
      "Iter  58 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  58 , ratio( RPF ): 0.9793541347801439\n",
      "Iter  58 , ratio( WF ): 0.8842735331460417\n",
      "Iter  59 , ratio( GBF ): 0.9718608667974731\n",
      "Iter  59 , ratio( RPF ): 0.9756715737701626\n",
      "Iter  59 , ratio( WF ): 0.8964441480511439\n",
      "Iter  60 , ratio( GBF ): 0.9049729440346215\n",
      "Iter  60 , ratio( RPF ): 0.9582531339301182\n",
      "Iter  60 , ratio( WF ): 0.9582531339301181\n",
      "Iter  61 , ratio( GBF ): 0.970693171587902\n",
      "Iter  61 , ratio( RPF ): 0.9999999999999998\n",
      "Iter  61 , ratio( WF ): 0.9999999999999998\n",
      "Iter  62 , ratio( GBF ): 0.9741481964996885\n",
      "Iter  62 , ratio( RPF ): 0.9644283307033779\n",
      "Iter  62 , ratio( WF ): 0.9651481143680574\n",
      "Iter  63 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  63 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  63 , ratio( WF ): 0.8764121024997177\n",
      "Iter  64 , ratio( GBF ): 0.9818057670775464\n",
      "Iter  64 , ratio( RPF ): 0.9400029213772662\n",
      "Iter  64 , ratio( WF ): 0.9548738724534224\n",
      "Iter  65 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  65 , ratio( RPF ): 0.9707885457463544\n",
      "Iter  65 , ratio( WF ): 0.9504154362748248\n",
      "Iter  66 , ratio( GBF ): 1.0\n",
      "Iter  66 , ratio( RPF ): 0.974505383667728\n",
      "Iter  66 , ratio( WF ): 0.9183264212229795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  67 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  67 , ratio( RPF ): 0.9097902502465927\n",
      "Iter  67 , ratio( WF ): 0.9233598776744112\n",
      "Iter  68 , ratio( GBF ): 0.9865902160882978\n",
      "Iter  68 , ratio( RPF ): 0.9865902160882978\n",
      "Iter  68 , ratio( WF ): 0.9162012826692455\n",
      "Iter  69 , ratio( GBF ): 0.9999999999999999\n",
      "Iter  69 , ratio( RPF ): 0.8883568991267317\n",
      "Iter  69 , ratio( WF ): 0.9386018665646141\n",
      "Iter  70 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  70 , ratio( RPF ): 0.9094654728715548\n",
      "Iter  70 , ratio( WF ): 0.9604095570085223\n",
      "Iter  71 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  71 , ratio( RPF ): 0.9889992661566175\n",
      "Iter  71 , ratio( WF ): 1.0000000000000002\n",
      "Iter  72 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  72 , ratio( RPF ): 1.0\n",
      "Iter  72 , ratio( WF ): 0.8105240616917686\n",
      "Iter  73 , ratio( GBF ): 0.9986717257988131\n",
      "Iter  73 , ratio( RPF ): 0.9808731368140314\n",
      "Iter  73 , ratio( WF ): 0.9691377115594366\n",
      "Iter  74 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  74 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  74 , ratio( WF ): 0.8187504033110717\n",
      "Iter  75 , ratio( GBF ): 0.9551624893541555\n",
      "Iter  75 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  75 , ratio( WF ): 0.8831118834827898\n",
      "Iter  76 , ratio( GBF ): 0.9999999999999999\n",
      "Iter  76 , ratio( RPF ): 0.981667181166107\n",
      "Iter  76 , ratio( WF ): 0.9912885629251408\n",
      "Iter  77 , ratio( GBF ): 1.0\n",
      "Iter  77 , ratio( RPF ): 0.9999999999999999\n",
      "Iter  77 , ratio( WF ): 0.9999999999999997\n",
      "Iter  78 , ratio( GBF ): 0.9999999999999997\n",
      "Iter  78 , ratio( RPF ): 0.9592471634344016\n",
      "Iter  78 , ratio( WF ): 0.9820322487758641\n",
      "Iter  79 , ratio( GBF ): 1.0000000000000004\n",
      "Iter  79 , ratio( RPF ): 0.9674329437022826\n",
      "Iter  79 , ratio( WF ): 0.974363668451172\n",
      "Iter  80 , ratio( GBF ): 0.9705489371219369\n",
      "Iter  80 , ratio( RPF ): 0.924812135777868\n",
      "Iter  80 , ratio( WF ): 0.9248121357778681\n",
      "Iter  81 , ratio( GBF ): 0.9896821908612147\n",
      "Iter  81 , ratio( RPF ): 0.9999999999999999\n",
      "Iter  81 , ratio( WF ): 0.8935251122637329\n",
      "Iter  82 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  82 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  82 , ratio( WF ): 1.0000000000000004\n",
      "Iter  83 , ratio( GBF ): 0.9976463559281338\n",
      "Iter  83 , ratio( RPF ): 0.9732452832243378\n",
      "Iter  83 , ratio( WF ): 0.9688476924751653\n",
      "Iter  84 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  84 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  84 , ratio( WF ): 0.961903885668708\n",
      "Iter  85 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  85 , ratio( RPF ): 0.9988570545575696\n",
      "Iter  85 , ratio( WF ): 0.9301221686520612\n",
      "Iter  86 , ratio( GBF ): 0.9653644529377967\n",
      "Iter  86 , ratio( RPF ): 0.9653644529377967\n",
      "Iter  86 , ratio( WF ): 0.9442821924083096\n",
      "Iter  87 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  87 , ratio( RPF ): 0.9651499866450242\n",
      "Iter  87 , ratio( WF ): 0.8753370775532208\n",
      "Iter  88 , ratio( GBF ): 1.0\n",
      "Iter  88 , ratio( RPF ): 0.9221085982702046\n",
      "Iter  88 , ratio( WF ): 0.9466758984925905\n",
      "Iter  89 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  89 , ratio( RPF ): 1.0000000000000002\n",
      "Iter  89 , ratio( WF ): 0.9206055844343595\n",
      "Iter  90 , ratio( GBF ): 1.0000000000000002\n",
      "Iter  90 , ratio( RPF ): 0.9280949048685471\n",
      "Iter  90 , ratio( WF ): 0.9280949048685471\n",
      "Iter  91 , ratio( GBF ): 0.9999999999999996\n",
      "Iter  91 , ratio( RPF ): 0.9999999999999998\n",
      "Iter  91 , ratio( WF ): 0.8726760206984463\n",
      "Iter  92 , ratio( GBF ): 0.9975407762806902\n",
      "Iter  92 , ratio( RPF ): 0.9912662448789143\n",
      "Iter  92 , ratio( WF ): 0.9736531670547519\n",
      "Iter  93 , ratio( GBF ): 0.9999999999999998\n",
      "Iter  93 , ratio( RPF ): 0.9591289624979304\n",
      "Iter  93 , ratio( WF ): 0.9410629772063486\n",
      "Iter  94 , ratio( GBF ): 0.9787886291616451\n",
      "Iter  94 , ratio( RPF ): 0.9906764984821026\n",
      "Iter  94 , ratio( WF ): 0.9906764984821028\n",
      "Iter  95 , ratio( GBF ): 1.0\n",
      "Iter  95 , ratio( RPF ): 0.980003326425669\n",
      "Iter  95 , ratio( WF ): 0.9846456808001008\n",
      "Iter  96 , ratio( GBF ): 0.980563902462594\n",
      "Iter  96 , ratio( RPF ): 0.9869354462469876\n",
      "Iter  96 , ratio( WF ): 0.9869354462469873\n",
      "Iter  97 , ratio( GBF ): 0.9846175082500328\n",
      "Iter  97 , ratio( RPF ): 0.9021671753773143\n",
      "Iter  97 , ratio( WF ): 0.8884450748008641\n",
      "Iter  98 , ratio( GBF ): 0.9697582271602013\n",
      "Iter  98 , ratio( RPF ): 0.9850868017322876\n",
      "Iter  98 , ratio( WF ): 0.9708966093990002\n",
      "Iter  99 , ratio( GBF ): 0.9846513708944071\n",
      "Iter  99 , ratio( RPF ): 0.9537884629447784\n",
      "Iter  99 , ratio( WF ): 0.9846513708944072\n"
     ]
    }
   ],
   "source": [
    "###TESTER\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Untitled17.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1BHHsLNfrq_nSoSu570m3osZ3Njbdncc9\n",
    "\"\"\"\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "#%matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "# Max-cut functions\n",
    "def InitializeGraph(n, min_weight, max_weight, dropout, seed = -1, graph_type=\"complete\", intercalation=None, modulo=None):\n",
    "    # Randomness\n",
    "    if graph_type == \"complete\":\n",
    "        if seed == -1:\n",
    "            W = np.random.uniform(low=min_weight, high=max_weight, size=(n,n))\n",
    "        else:\n",
    "            local_state = np.random.RandomState(seed)\n",
    "            W = local_state.uniform(low=min_weight, high=max_weight, size=(n,n))\n",
    "        # Dropout with connected\n",
    "        if dropout>0:\n",
    "            connected = False\n",
    "            while not connected:\n",
    "                if seed == -1:\n",
    "                    D = np.random.choice([0,1], size=(n,n), replace=True, p=[dropout, 1-dropout])\n",
    "                else:\n",
    "                    D = local_state.choice([0,1], size=(n,n), replace=True, p=[dropout, 1-dropout])\n",
    "                W_dropped = np.multiply(W,D)\n",
    "                \n",
    "                # Check for connectivity\n",
    "                i_lower = np.tril_indices(n, -1)\n",
    "                W_dropped[i_lower] = W_dropped.T[i_lower]\n",
    "                # Make sure diagonal is empty\n",
    "                np.fill_diagonal(W_dropped, 0)\n",
    "                W_sym = nx.from_numpy_matrix(W_dropped)\n",
    "                if nx.is_connected(W_sym):\n",
    "                    connected = True\n",
    "                    W = np.copy(W_dropped)     \n",
    "    elif graph_type == \"cycle\":\n",
    "        if seed == -1:\n",
    "            weights = np.random.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        else:\n",
    "            local_state = np.random.RandomState(seed)\n",
    "            weights = local_state.uniform(low=min_weight, high=max_weight, size=(n,n))\n",
    "        W = np.zeros((n,n))\n",
    "        i = 0\n",
    "        j = 1\n",
    "        for k in range(n-1):\n",
    "            W[i,j] = weights[k]\n",
    "            i+=1\n",
    "            j+=1\n",
    "        # Add last weight\n",
    "        W[0, n-1] = weights[n-1]                \n",
    "    elif graph_type == \"regular_log(n)\":\n",
    "        degseq = np.repeat(np.floor(np.log(n)), n)\n",
    "        adjMatr = AdjacencyMatrixDegree(degseq)\n",
    "        if seed == -1:\n",
    "            W = np.random.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        else:\n",
    "            local_state = np.random.RandomState(seed)\n",
    "            W = local_state.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        W = np.multiply(W,adjMatr)\n",
    "    elif graph_type == \"intercalate\":\n",
    "        if seed == -1:\n",
    "            weights = np.random.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        else:\n",
    "            local_state = np.random.RandomState(seed)\n",
    "            weights = local_state.uniform(low=min_weight, high=max_weight, size=(n,n))\n",
    "        adjMatr = np.zeros((n,n))\n",
    "        # Fill diagonals above the main diagonal\n",
    "        for k in range(intercalation):\n",
    "            for i in range(n-k-1):\n",
    "                adjMatr[i, i+k+1] = 1\n",
    "        # Fill upper right corner\n",
    "        for j in range(intercalation):\n",
    "            for i in range(j+1):\n",
    "                adjMatr[j-i, n-i-1]=1\n",
    "        W = np.multiply(weights, adjMatr)\n",
    "    elif graph_type == \"modulo\":\n",
    "        if seed == -1:\n",
    "            weights = np.random.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        else:\n",
    "            local_state = np.random.RandomState(seed)\n",
    "            weights = local_state.uniform(low=min_weight, high=max_weight, size=(n,n))\n",
    "        adjMatr = np.zeros((n,n))\n",
    "        # Create circle\n",
    "        for i in range(n-1):\n",
    "            adjMatr[i, i+1] = 1\n",
    "        # Fill upper right corner\n",
    "        adjMatr[0, n-1]=1\n",
    "        # Add other connections\n",
    "        # Fill diagonals above the main diagonal\n",
    "        for i in range(n-modulo):\n",
    "            adjMatr[i, i+modulo] = 1\n",
    "        # Fill upper right corner\n",
    "        for i in range(modulo):\n",
    "            adjMatr[modulo-1-i, n-i-1]=1\n",
    "        W = np.multiply(weights, adjMatr)\n",
    "    \n",
    "    # Copy upper diagonal to lower diagonal (only the upper perturbation counts)\n",
    "    i_lower = np.tril_indices(n, -1)\n",
    "    W[i_lower] = W.T[i_lower]\n",
    "    # Make sure diagonal is empty\n",
    "    np.fill_diagonal(W, 0)\n",
    "    \n",
    "    return W\n",
    "\n",
    "def InitializeFlatGraph(n, min_weight, max_weight, dropout = 0, seed = -1, graph_type = \"complete\", intercalation = None, modulo = None):\n",
    "    if graph_type == \"complete\":\n",
    "        if seed == -1:\n",
    "            W = np.random.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        else:\n",
    "            local_state = np.random.RandomState(seed)\n",
    "            W = local_state.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        if dropout>0:            \n",
    "            connected = False\n",
    "            while connected == False:\n",
    "                if seed == -1:\n",
    "                    D = np.random.choice([0,1], size=n, replace=True, p=[dropout, 1-dropout])\n",
    "                else:\n",
    "                    D = local_state.choice([0,1], size=n, replace=True, p=[dropout, 1-dropout])\n",
    "                # Check if the dropped out matrix is connected\n",
    "                # Make it a symmetric matrix\n",
    "                D_sym = SymmetricMatrix(D)\n",
    "                # Check if it resembles a connected graph\n",
    "                D_sym = nx.from_numpy_matrix(D_sym)\n",
    "                if nx.is_connected(D_sym):\n",
    "                    connected = True\n",
    "            # Once we have a conencted graph, add weights\n",
    "            W = np.multiply(W,D)       \n",
    "    elif graph_type == \"cycle\":\n",
    "        if seed == -1:\n",
    "            weights = np.random.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        else:\n",
    "            local_state = np.random.RandomState(seed)\n",
    "            weights = local_state.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        W = np.zeros((n,n))\n",
    "        i = 0\n",
    "        j = 1\n",
    "        for k in range(n-1):\n",
    "            W[i,j] = weights[k]\n",
    "            i+=1\n",
    "            j+=1\n",
    "        # Add last weight\n",
    "        W[0, n-1] = weights[n-1]\n",
    "        i_lower = np.tril_indices(n, -1)\n",
    "        W[i_lower] = W.T[i_lower]\n",
    "        # Make sure diagonal is empty\n",
    "        np.fill_diagonal(W, 0)\n",
    "        W = np.copy(W[np.triu_indices_from(W, k = 1)])\n",
    "    elif graph_type == \"regular_log(n)\":\n",
    "        degseq = np.repeat(np.floor(np.log(n)), n)\n",
    "        adjMatr = AdjacencyMatrixDegree(degseq)\n",
    "        if seed == -1:\n",
    "            W = np.random.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        else:\n",
    "            local_state = np.random.RandomState(seed)\n",
    "            W = local_state.uniform(low=min_weight, high=max_weight, size=n)\n",
    "        W = np.multiply(W,adjMatr)\n",
    "        W = np.copy(W[np.triu_indices_from(W, k = 1)])\n",
    "    elif graph_type == \"intercalate\":\n",
    "        W = InitializeGraph(n, min_weight, max_weight, dropout, seed, graph_type, intercalation)\n",
    "        W = np.copy(W[np.triu_indices_from(W, k = 1)])\n",
    "    elif graph_type == \"modulo\":\n",
    "        W = InitializeGraph(n, min_weight, max_weight, dropout, seed, graph_type, None, modulo)\n",
    "        W = np.copy(W[np.triu_indices_from(W, k = 1)])\n",
    "    return W\n",
    "\n",
    "def AdjacencyMatrixDegree(degseq):\n",
    "    # n is number of vertices  \n",
    "    n = len(degseq)\n",
    "    mat = [[0] * n for i in range(n)] \n",
    "    for i in range(n): \n",
    "        for j in range(i + 1, n): \n",
    "            # For each pair of vertex decrement  \n",
    "            # the degree of both vertex.  \n",
    "            if (degseq[i] > 0 and degseq[j] > 0): \n",
    "                degseq[i] -= 1\n",
    "                degseq[j] -= 1\n",
    "                mat[i][j] = 1\n",
    "                mat[j][i] = 1\n",
    "    return mat\n",
    "\n",
    "def GetAllPossibleAdjacencyFlatMatrixes(n):\n",
    "    import itertools\n",
    "    flatMatrixes = list(itertools.product([0, 1], repeat=n))\n",
    "    return flatMatrixes\n",
    "\n",
    "def GetKRandomPartition(n, k, seed = -1):\n",
    "    partition = {}\n",
    "    if seed == -1:\n",
    "        for i in range(n):\n",
    "            partition[i]=np.random.randint(low=0, high=k, size=1)[0]\n",
    "    else:\n",
    "        local_state = np.random.RandomState(seed)\n",
    "        for i in range(n):\n",
    "            partition[i]=local_state.randint(low=0, high=k, size=1)[0]\n",
    "    return partition\n",
    "\n",
    "# G stands for special ill-posed matrixes\n",
    "def GetGWeightMatrix(g):\n",
    "    if g == 1:\n",
    "        G = np.array([[0, 7, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 6, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 5, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 1, 3, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 1, 1],\n",
    "             [0, 0, 0, 0, 0, 0, 2, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0]]).astype(float)\n",
    "    elif g == 2:\n",
    "        G = np.array([\n",
    "               [0, 51, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 8, 0, 10, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 8, 0, 8, 5, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 4, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).astype(float)\n",
    "    else:\n",
    "        raise(\"No\")\n",
    "    n = np.size(G, 1)\n",
    "    i_lower = np.tril_indices(n, -1)\n",
    "    G[i_lower] = G.T[i_lower]\n",
    "    return G\n",
    "\n",
    "def WeightsStats(W):\n",
    "    print(\"Weight statistics\\n\")\n",
    "    mean = []\n",
    "    median = []\n",
    "    std = []\n",
    "    min_w = []\n",
    "    max_w = []\n",
    "    n = []\n",
    "    W_without_0_edges = np.copy(W[W!=0])\n",
    "    mean.append(W_without_0_edges.mean())\n",
    "    median.append(np.median(W_without_0_edges))\n",
    "    std.append(W_without_0_edges.std())\n",
    "    min_w.append(W_without_0_edges.min())\n",
    "    max_w.append(W_without_0_edges.max())\n",
    "    s = W_without_0_edges.shape[0]\n",
    "    s = int((1+np.sqrt(1+4*2*s))/2)+1\n",
    "    n.append(s)\n",
    "    print(tabulate(list(zip(*[n, mean, median, std, min_w, max_w])), \n",
    "                   headers=[\"n\", 'mean', 'median', 'std', \"min_weight\", \"max_weight\"], floatfmt=\".3f\"))\n",
    "    return\n",
    "\n",
    "def Get0Partition(n):\n",
    "    partition = {}\n",
    "    for i in range(n):\n",
    "        partition[i]=0\n",
    "    return partition\n",
    "\n",
    "def Get1Partition(n):\n",
    "    partition = {}\n",
    "    for i in range(n):\n",
    "        partition[i]=1\n",
    "    return partition\n",
    "\n",
    "def GetStupidPartition(n):\n",
    "    partition = {}\n",
    "    for i in range(n):\n",
    "        partition[i]=-1\n",
    "    return partition\n",
    "\n",
    "def GetInitialPartition(n, k, initial_partition_type, seed = -1):\n",
    "    if initial_partition_type == \"random\":\n",
    "        initial_partition = GetKRandomPartition(n, k, seed)\n",
    "    if initial_partition_type == \"0\":\n",
    "        initial_partition = Get0Partition(n)\n",
    "    if initial_partition_type == \"1\":\n",
    "        initial_partition = Get1Partition(n)\n",
    "    return initial_partition\n",
    "\n",
    "def CutCost(W, partition, n, k):\n",
    "    z = 0\n",
    "    identity = np.identity(k)\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            new_edge = (1-identity[partition[i], partition[j]])*W[i,j]\n",
    "            z += new_edge\n",
    "    return z\n",
    "        \n",
    "def CutGainAfterFlip(W, initial_partition, final_partition, n):\n",
    "    # Vi: initial partition of the vertex v\n",
    "    # Vj: final partition of the vertex v\n",
    "    # z: current cut\n",
    "    weights_to_add = 0\n",
    "    weights_to_substract = 0\n",
    "    \n",
    "    diff_partition = {key: initial_partition[key] - final_partition.get(key, 0) for key in initial_partition}\n",
    "    \n",
    "    # v: vertex that flipped\n",
    "    v = [key for key, val in diff_partition.items() if val!=0][0]\n",
    "    v_old_partition = initial_partition[v]\n",
    "    v_new_partition = final_partition[v]\n",
    "    \n",
    "    # Vertices belonging to the old group and the new group\n",
    "    vertices_in_old_partition = [key  for (key, value) in initial_partition.items() if value == v_old_partition]\n",
    "    vertices_in_new_partition = [key  for (key, value) in initial_partition.items() if value == v_new_partition]\n",
    "\n",
    "    for vi in vertices_in_old_partition:\n",
    "        if vi == v:\n",
    "            continue\n",
    "        else:\n",
    "            weights_to_add += W[v, vi]\n",
    "    for vj in vertices_in_new_partition:\n",
    "        weights_to_substract += W[v, vj]\n",
    "    z = weights_to_add - weights_to_substract\n",
    "    return z\n",
    "            \n",
    "def SolveMaxCut(W, n, k, z, initial_partition, heuristic, seed = -1):\n",
    "    tol = 1e-8\n",
    "    maxIter = 100000\n",
    "    it = 0\n",
    "    \n",
    "    zt1 = -10000\n",
    "    zt2 = CutCost(W, initial_partition, n, k)\n",
    "    \n",
    "    # In case the cut is already optimal\n",
    "    new_z = zt2\n",
    "    \n",
    "    # Store old and new partition\n",
    "    old_partition = GetStupidPartition(n)\n",
    "    new_partition = initial_partition\n",
    "    \n",
    "    start = time.time()\n",
    "    if heuristic == \"GBF\":\n",
    "        # Greedy Best Flip\n",
    "        while(old_partition!=new_partition and it<maxIter):\n",
    "            old_partition = new_partition\n",
    "            new_partition, new_z = GreedyBestFlip(W, new_partition, n, k, zt2)\n",
    "            zt1 = zt2\n",
    "            zt2 = new_z\n",
    "            if old_partition!=new_partition:\n",
    "                it = it + 1\n",
    "    elif heuristic == \"RPF\":\n",
    "        # Random Positive Flip\n",
    "         while(old_partition!=new_partition and it<maxIter):\n",
    "            old_partition = new_partition\n",
    "            new_partition, new_z = RandomPositiveFlip(W, new_partition, n, k, zt2, seed)\n",
    "            zt1 = zt2\n",
    "            zt2 = new_z\n",
    "            if old_partition!=new_partition:\n",
    "                it = it + 1\n",
    "    elif heuristic == \"WF\":\n",
    "        # Worst Flip\n",
    "         while(old_partition!=new_partition and it<maxIter):\n",
    "            old_partition = new_partition\n",
    "            new_partition, new_z = WorstFlip(W, new_partition, n, k, zt2)\n",
    "            zt1 = zt2\n",
    "            zt2 = new_z\n",
    "            if old_partition!=new_partition:\n",
    "                it = it + 1\n",
    "\n",
    "    elif heuristic == \"FNF\":\n",
    "        # First Next Flip\n",
    "        # Only for testing purposes\n",
    "        iters_fnf = 3\n",
    "        for i in range(iters_fnf):\n",
    "            partition, new_z = FirstNextFlip(W, partition, n, k, zt2)\n",
    "            zt1 = zt2\n",
    "            zt2 = new_z\n",
    "            if old_partition!=new_partition:\n",
    "                it = it + 1\n",
    "            \n",
    "    end = time.time()\n",
    "    elapsed_time = np.round(end - start, 4)\n",
    "    # The last step would return the same partition, so it-1\n",
    "    return new_partition, new_z, elapsed_time, it\n",
    "\n",
    "def SolveGlobalMaxCut(W, n, k):\n",
    "    # Get all possible partitions\n",
    "    import itertools\n",
    "    k_vector = range(k)\n",
    "    allPartitions = list(itertools.product(k_vector, repeat=n))\n",
    "    n_partitions = len(allPartitions)\n",
    "    max_cut = -100000\n",
    "    best_partition = allPartitions[0]\n",
    "    start = time.time()\n",
    "    for partition in allPartitions:\n",
    "        c = CutCost(W, partition, n, k)\n",
    "        if c > max_cut:\n",
    "            max_cut = c\n",
    "            best_partition = partition\n",
    "    end = time.time()\n",
    "    elapsed_time = np.round(end - start, 4)\n",
    "    # Create the partition dictionary\n",
    "    best_partition = list(best_partition)\n",
    "    keys = range(0, n)\n",
    "    best_partition_d = {k:v for k,v in zip(keys, best_partition)}\n",
    "    # The last step would return the same partition, so it-1\n",
    "    return best_partition_d, max_cut, elapsed_time\n",
    "\n",
    "def GurobiSolveMaxCut(W, n):\n",
    "    # Initialize model\n",
    "    m = gp.Model(\"max-cut\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    # Define variables\n",
    "    # x: partition of each node?\n",
    "    # z: edge is present in the cut?\n",
    "    z = m.addVars(n, n, vtype=GRB.BINARY, name=\"edges\")\n",
    "    x = m.addVars(n, vtype=GRB.BINARY, name='partitions')\n",
    "    \n",
    "    \n",
    "    # Add constrains\n",
    "    m.addConstrs((z[i,j]<=x[i]+x[j] for i in range(n) for j in range(n)), \"C1\")\n",
    "    m.addConstrs((z[i,j]+x[i]+x[j]<=2 for i in range(n) for j in range(n)), \"C2\")\n",
    "    \n",
    "    # Set objective function\n",
    "    obj_f = gp.quicksum(1/2*W[(i,j)]*z[(i,j)] for i in range(n) for j in range(n))\n",
    "    m.setObjective(obj_f, GRB.MAXIMIZE)\n",
    "    \n",
    "    # Go\n",
    "    m.optimize()\n",
    "    \n",
    "    # Get solution\n",
    "    best_cut = m.getObjective().getValue()\n",
    "    \n",
    "    # Get final partition\n",
    "    nodes = m.getVars()\n",
    "    best_partition = {}\n",
    "    for i in range(n):\n",
    "        best_partition[i] = nodes[i].x\n",
    "    \n",
    "    return best_partition, best_cut\n",
    "    \n",
    "def SymmetricMatrix(W):\n",
    "    m = len(W)\n",
    "    n = int((1+np.sqrt(1+4*2*m))/2)\n",
    "    A = np.zeros(shape=(n, n))\n",
    "    # k runs along W\n",
    "    k = 0\n",
    "    # Fill upper diagonal\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            A[i,j]=W[k]\n",
    "            k+=1\n",
    "    # Fill lower diagonal\n",
    "    i_lower = np.tril_indices(n, -1)\n",
    "    A[i_lower] = A.T[i_lower]\n",
    "    return A\n",
    "\n",
    "def ScaleMatrix(W, a, b):\n",
    "    non_zeros = np.nonzero(W)\n",
    "    min_W = W[non_zeros].min()\n",
    "    max_W = W.max()\n",
    "    # Keep structure\n",
    "    W_scaled = np.copy(W.astype(float))\n",
    "    W_scaled[non_zeros] = (b-a)*((W[non_zeros]-min_W)/(max_W-min_W))+a\n",
    "    return W_scaled\n",
    "\n",
    "def NumpyToCsv(array, filename):\n",
    "    np.savetxt(str(filename) + \".csv\", array, delimiter=\";\")\n",
    "\n",
    "def DeleteTempResults(filename):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    return\n",
    "\n",
    "def CsvToNumpy(filename):\n",
    "    return np.genfromtxt(str(filename) + \".csv\", delimiter=\";\")\n",
    "\n",
    "def KolmogorovSmirnovTest(x1, x2, alpha):\n",
    "    st, p = stats.ks_2samp(x1, x2)\n",
    "    n1 = len(x1)\n",
    "    n2 = len(x2)\n",
    "    size_term = np.sqrt((n1+n2)/(n1*n2))\n",
    "    if alpha == 0.05:\n",
    "        d = size_term*1.36\n",
    "    elif alpha == 0.025:\n",
    "        d = size_term*1.48\n",
    "    else:\n",
    "        return\n",
    "    if st < d:\n",
    "        print(\"Both distributions are the same with probability\", 100*(1-alpha), \"%\")\n",
    "        print(st, \"<\", d)\n",
    "    if st > d:\n",
    "        print(\"Reject null hypothesis: different distributions with probability\", 100*(1-alpha), \"%\")\n",
    "        print(st, \">\", d)\n",
    "    return\n",
    "    \n",
    "# Meshgrid - No need to parallelize\n",
    "def MeshGrid3dMaxCut(k, min_weight, max_weight, initial_partition_type, n_points_ax, n_iters, complexity, heuristic, sigma):\n",
    "    weights_size = 3\n",
    "    x = np.zeros(shape=(np.power(n_points_ax+1, 3), weights_size))\n",
    "    f = np.zeros(np.power(n_points_ax+1, 3))\n",
    "    # p runs over all points\n",
    "    p = 0\n",
    "    for i in range(n_points_ax+1):\n",
    "        x_val = min_weight + (max_weight-min_weight)*i/n_points_ax\n",
    "        for j in range(n_points_ax+1):\n",
    "            y_val = min_weight + (max_weight-min_weight)*j/n_points_ax\n",
    "            for l in range(n_points_ax+1):\n",
    "                z_val = min_weight + (max_weight-min_weight)*l/n_points_ax\n",
    "                w_flat = [x_val, y_val, z_val]\n",
    "                w = SymmetricMatrix(w_flat)\n",
    "                steps = np.zeros(n_iters)\n",
    "                for it in range(n_iters):\n",
    "                    initial_partition = GetInitialPartition(3, k, initial_partition_type)\n",
    "                    initial_z = CutCost(w, initial_partition, 3, k)\n",
    "                    if complexity == \"average\":\n",
    "                        _p, _z, _t, steps[it] = SolveMaxCut(w, 3, k, initial_z, initial_partition, heuristic)\n",
    "                    elif complexity == \"smoothed\":\n",
    "                        # n_iters is also used for n_perturbations\n",
    "                        steps[it] = SmoothedComplexity(w_flat, 3, k, initial_partition_type, 0, n_iters, heuristic, sigma)\n",
    "                f[p] = np.mean(steps)\n",
    "                x[p] = [x_val, y_val, z_val]\n",
    "                p+=1\n",
    "    return x, f\n",
    "\n",
    "def PlotMeshGrid3d(x, f, title, colorsMap='jet'):\n",
    "    cm = plt.get_cmap(colorsMap)\n",
    "    cNorm = matcolors.Normalize(vmin=min(f), vmax=max(f))\n",
    "    scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(x[:,0], x[:,1], x[:,2], c=scalarMap.to_rgba(f))\n",
    "    plt.xticks(np.arange(min(x[:,0]), max(x[:,0])+1, 0.5))\n",
    "    plt.yticks(np.arange(min(x[:,1]), max(x[:,1])+1, 0.5))\n",
    "    scalarMap.set_array(f)\n",
    "    fig.colorbar(scalarMap)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot results\n",
    "def GetColorsVector(n):\n",
    "    all_colors = [\"blue\", \"red\", \"green\", \"black\", \"purple\"]\n",
    "    #\"orange\", \"green\", \"red\", \"black\", \"purple\", \"grey\"]\n",
    "    return all_colors[:n]\n",
    "\n",
    "def PlotGraph(W, partition = None, ax=None):\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    G = nx.from_numpy_matrix(np.round(W, 3))\n",
    "    # Relabel nodes\n",
    "    #mapping = {0: '1', 1: '2', 2: '3'}\n",
    "    #G = nx.relabel_nodes(G, mapping)\n",
    "    pos = nx.circular_layout(G)\n",
    "    \n",
    "    # Create edge labels\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    edges, weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    \n",
    "    # Draw the graph according to node positions\n",
    "    if partition is not None:\n",
    "        colors = np.fromiter(partition.values(), dtype=int)\n",
    "        if ax is None:\n",
    "            nx.draw(G, pos, with_labels=True, node_color=colors, edgelist=edges, edge_color=weights, width=5.0, edge_cmap=plt.cm.Blues)\n",
    "        else:\n",
    "            nx.draw(G, pos, with_labels=True, node_color=colors, edgelist=edges, edge_color=weights, width=5.0, edge_cmap=plt.cm.Blues, ax=ax)\n",
    "    else:\n",
    "        if ax is None:\n",
    "            nx.draw(G, pos, with_labels=True, edgelist=edges, edge_color=weights, width=5.0, edge_cmap=plt.cm.Blues)\n",
    "        else:\n",
    "            nx.draw(G, pos, with_labels=True, edgelist=edges, edge_color=weights, width=5.0, edge_cmap=plt.cm.Blues, ax=ax)\n",
    "    # Draw edge labels according to node positions\n",
    "    #nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "    if ax is None:\n",
    "        plt.show()    \n",
    "    return\n",
    "\n",
    "def PlotWeightsHistogram(W):\n",
    "    # Start plot\n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    # Plot histogram of weights\n",
    "    W_without_0_edges = np.copy(W[W!=0])\n",
    "    plt.hist(W_without_0_edges, bins=20, color='blue')\n",
    "    plt.title('Weight distribution', fontsize=8)\n",
    "    # Do KSTest with uniform\n",
    "    n = len(W)\n",
    "    uniform_sample = np.random.uniform(low=-1, high=1, size=n)\n",
    "    KolmogorovSmirnovTest(W, uniform_sample, alpha=0.025)\n",
    "    # Histogram of the sum of the edges from each vertex\n",
    "    sum_of_edges = np.sum(SymmetricMatrix(W), axis = 0)\n",
    "    plt.subplot(212)\n",
    "    plt.hist(sum_of_edges, bins=10)\n",
    "    plt.title('Sum of edges', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Do KSTest with artificial sample (assume independency)\n",
    "    #artificial_sample = np.zeros(n)\n",
    "    #for i in range(n):\n",
    "    #    artificial_sample[i] = np.sum(np.random.uniform(low=-1, high=1, size=n-1))\n",
    "    #KolmogorovSmirnovTest(sum_of_edges, artificial_sample, 0.05)\n",
    "    return\n",
    "\n",
    "def PlotRegressionResults(nodes, steps_mean, steps_sd, with_errorbars, r_var, r_var_label, method):\n",
    "    \n",
    "    # Convert X axis according to method\n",
    "    x = nodes\n",
    "    if method==\"polynomial\":\n",
    "        x = np.log(x.reshape(-1, 1))\n",
    "    if method == \"quasipolynomial\":\n",
    "        x = np.log(x.reshape(-1, 1))*x.reshape(-1, 1)\n",
    "\n",
    "    cmap = GetColorsVector(len(r_var))\n",
    "    \n",
    "    # t runs over all columns of steps_mean\n",
    "    t=0\n",
    "    slopes=[]\n",
    "    intercepts=[]\n",
    "    r_values=[]\n",
    "    p_values=[]\n",
    "    std_errs=[]\n",
    "\n",
    "    # Create a new plot\n",
    "    plt.figure(np.random.randint(501, 1000))\n",
    "    \n",
    "    for r_v in r_var:\n",
    "        # Convert Y axis according to method\n",
    "        y = steps_mean[:,t]\n",
    "        if (method==\"polynomial\") or (method==\"exponential\") or (method==\"quasipolynomial\"):\n",
    "            y_log = np.log(y)\n",
    "        plt.scatter(x, y_log, c=cmap[t])\n",
    "        if with_errorbars:\n",
    "            y_sd = steps_sd[:, t]/y\n",
    "            plt.errorbar(x,y_log,yerr=y_sd, linestyle=\"None\", c=cmap[t])\n",
    "\n",
    "        # Linear regression\n",
    "        slope, intercept, r_value, p_value, std_err = stats.mstats.linregress(x,y_log)\n",
    "\n",
    "        # Store results\n",
    "        slopes.append(slope)\n",
    "        intercepts.append(intercept)\n",
    "        r_values.append(r_value)\n",
    "        p_values.append(p_value)\n",
    "        std_errs.append(std_err)\n",
    "\n",
    "        # Linear regression prediction\n",
    "        y_reg = intercept + slope*x\n",
    "        plt.plot(x, y_reg, label=str(r_var_label) + '=' + str(r_v), c=cmap[t])\n",
    "        t+=1\n",
    "\n",
    "    if method==\"polynomial\":\n",
    "        plt.title('Polynomial behavior')     \n",
    "        plt.xlabel('ln(Nodes)') \n",
    "        plt.ylabel('ln(Steps)')\n",
    "    \n",
    "    if method==\"exponential\":\n",
    "        plt.title('Exponential behavior')     \n",
    "        plt.xlabel('Nodes') \n",
    "        plt.ylabel('ln(Steps)')\n",
    "        \n",
    "    if method==\"quasipolynomial\":\n",
    "        plt.title('Quasiplynomial behavior')     \n",
    "        plt.xlabel('ln(Nodes)*Nodes') \n",
    "        plt.ylabel('ln(Steps)')\n",
    "    \n",
    "    plt.legend()        \n",
    "    plt.show()\n",
    "\n",
    "    # Print table\n",
    "    print(\"Regression results:\\n\")\n",
    "    print(tabulate(list(zip(*[r_var, slopes, intercepts, r_values])), headers=[r_var_label, 'slope', 'intercept', 'r_value'], floatfmt=\".3f\"))\n",
    "    \n",
    "    return slopes, intercepts\n",
    "    \n",
    "def PlotResults(nodes, steps_mean, steps_sd, with_errorbars, r_var, r_var_label, xlabel = \"Nodes\", ylabel = \"Steps\"):\n",
    "    #r_var is running variable\n",
    "    \n",
    "    # Show results for each r_var\n",
    "    x = nodes.reshape(-1, 1)\n",
    "\n",
    "    # Legend\n",
    "    r_var_labels=[]\n",
    "\n",
    "    # t runs over all columns of steps_mean\n",
    "    t=0\n",
    "\n",
    "    cmap = GetColorsVector(len(r_var))\n",
    "    \n",
    "    # Create a new plot\n",
    "    plt.figure(np.random.randint(0, 500))\n",
    "    \n",
    "    for r_v in r_var:\n",
    "        run_steps = steps_mean[:,t]\n",
    "        plt.scatter(x, run_steps, c=cmap[t])\n",
    "        if with_errorbars:\n",
    "            run_steps_sd = steps_sd[:, t]\n",
    "            plt.errorbar(x,run_steps,yerr=run_steps_sd, linestyle=\"None\", c=cmap[t])\n",
    "        r_var_labels.append(str(r_var_label) + \"=\" + str(r_v))\n",
    "        t+=1\n",
    "\n",
    "    plt.title(str(xlabel) + \" vs. \" + str(ylabel)) \n",
    "    plt.xlabel(xlabel) \n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(r_var_labels)\n",
    "    plt.show()\n",
    "    \n",
    "def PlotResultsSmoothed(nodes, steps_mean, steps_sd, with_errorbars, r_var, r_var_label, sigma, withUpperBound):\n",
    "    #r_var is running variable\n",
    "    \n",
    "    # Show results for each r_var\n",
    "    x = nodes.reshape(-1, 1)\n",
    "\n",
    "    # Legend\n",
    "    r_var_labels=[]\n",
    "\n",
    "    # t runs over all columns of steps_mean\n",
    "    t=0\n",
    "    \n",
    "    # Create a new plot\n",
    "    plt.figure(np.random.randint(1001, 1500))\n",
    "\n",
    "    for r_v in r_var:\n",
    "        run_steps = steps_mean[:,t]\n",
    "        plt.scatter(x, run_steps)\n",
    "        if with_errorbars:\n",
    "            run_steps_sd = steps_sd[:, t]\n",
    "            plt.errorbar(x,run_steps,yerr=run_steps_sd, linestyle=\"None\")\n",
    "        r_var_labels.append(str(r_var_label) + \"=\" + str(r_v))\n",
    "        t+=1\n",
    "    # Assume gaussian\n",
    "    if withUpperBound:\n",
    "        phi = 1/np.sqrt(2*np.pi*sigma*sigma)\n",
    "        upper_bound = phi*np.power(nodes, 7.83)\n",
    "        plt.plot(nodes, upper_bound, color='red', linewidth=1.0, linestyle='--')\n",
    "    plt.title('Steps vs. Nodes') \n",
    "    plt.xlabel('Nodes') \n",
    "    plt.ylabel('Steps')\n",
    "    plt.legend(r_var_labels)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def PlotTwoRegressionResults(nodes1, steps_mean1, steps_sd1, nodes2, steps_mean2, steps_sd2, with_errorbars, r_var, r_var_label, method, labels):\n",
    "    \n",
    "    # Create a new plot\n",
    "    plt.figure(np.random.randint(501, 1000))\n",
    "\n",
    "    # t runs over all columns of steps_mean\n",
    "    t=0\n",
    "    slopes1=[]\n",
    "    intercepts1=[]\n",
    "    r_values1=[]\n",
    "    p_values1=[]\n",
    "    std_errs1=[]    \n",
    "    # Convert X axis according to method\n",
    "    x1 = nodes1\n",
    "    if method==\"polynomial\":\n",
    "        x1 = np.log(x1.reshape(-1, 1))\n",
    "    if method == \"quasipolynomial\":\n",
    "        x1 = np.log(x1.reshape(-1, 1))*x1.reshape(-1, 1)\n",
    "    \n",
    "    # For the averae case, we have to reduce the number of vertices so that the have similar lengths\n",
    "    last_index = np.argmax(nodes1>np.max(nodes2))\n",
    "    if last_index == 0:\n",
    "        last_index = len(x1-1)\n",
    "    x1 = x1[:last_index]\n",
    "    steps_mean1 = steps_mean1[:last_index]\n",
    "    steps_sd1 = steps_sd1[:last_index]\n",
    "    \n",
    "    for r_v in r_var:\n",
    "        # Convert Y axis according to method\n",
    "        y1 = steps_mean1[:,t]\n",
    "        if (method==\"polynomial\") or (method==\"exponential\") or (method==\"quasipolynomial\"):\n",
    "            y1 = np.log(y1)\n",
    "        plt.scatter(x1, y1, c = \"darkred\", alpha=0.5)\n",
    "        if with_errorbars:\n",
    "            if len(steps_sd1)>0:\n",
    "                y_sd1 = steps_sd1[:, t]\n",
    "                plt.errorbar(x1,y1,yerr=y_sd1, linestyle=\"None\", c = \"darkred\", alpha=0.5)\n",
    "\n",
    "        # Linear regression\n",
    "        slope1, intercept1, r_value1, p_value1, std_err1 = stats.mstats.linregress(x1,y1)\n",
    "\n",
    "        # Store results\n",
    "        slopes1.append(slope1)\n",
    "        intercepts1.append(intercept1)\n",
    "        r_values1.append(r_value1)\n",
    "        p_values1.append(p_value1)\n",
    "        std_errs1.append(std_err1)\n",
    "\n",
    "        # Linear regression prediction\n",
    "        y_reg1 = intercept1 + slope1*x1\n",
    "        plt.plot(x1, y_reg1, label=labels[0], c = \"red\")\n",
    "        t+=1\n",
    "        \n",
    "    # t runs over all columns of steps_mean\n",
    "    t=0\n",
    "    slopes2=[]\n",
    "    intercepts2=[]\n",
    "    r_values2=[]\n",
    "    p_values2=[]\n",
    "    std_errs2=[]   \n",
    "    \n",
    "    # X2 is smoothed, therefore no error bars\n",
    "    # Convert X axis according to method\n",
    "    x2 = nodes2\n",
    "    if method==\"polynomial\":\n",
    "        x2 = np.log(x2.reshape(-1, 1))\n",
    "    if method == \"quasipolynomial\":\n",
    "        x2 = np.log(x2.reshape(-1, 1))*x2.reshape(-1, 1)\n",
    "    \n",
    "    for r_v in r_var:\n",
    "        # Convert Y axis according to method\n",
    "        y2 = steps_mean2[:,t]\n",
    "        if (method==\"polynomial\") or (method==\"exponential\") or (method==\"quasipolynomial\"):\n",
    "            y2 = np.log(y2)\n",
    "        plt.scatter(x2, y2, c = \"darkblue\", alpha=0.5)\n",
    "        if with_errorbars:\n",
    "            if len(steps_sd2)>0:\n",
    "                y_sd2 = steps_sd2[:, t]\n",
    "                plt.errorbar(x2,y2,yerr=y_sd2, linestyle=\"None\", c = \"darkblue\", alpha=0.5)\n",
    "\n",
    "        # Linear regression\n",
    "        slope2, intercept2, r_value2, p_value2, std_err2 = stats.mstats.linregress(x2,y2)\n",
    "\n",
    "        # Store results\n",
    "        slopes2.append(slope2)\n",
    "        intercepts2.append(intercept2)\n",
    "        r_values2.append(r_value2)\n",
    "        p_values2.append(p_value2)\n",
    "        std_errs2.append(std_err2)\n",
    "\n",
    "        # Linear regression prediction\n",
    "        y_reg2 = intercept2 + slope2*x2\n",
    "        plt.plot(x2, y_reg2, label=labels[1], c = \"blue\")\n",
    "        t+=1\n",
    "\n",
    "    if method==\"polynomial\":\n",
    "        plt.title('Polynomial behavior')     \n",
    "        plt.xlabel('ln(Nodes)') \n",
    "        plt.ylabel('ln(Steps)')\n",
    "    \n",
    "    if method==\"exponential\":\n",
    "        plt.title('Exponential behavior')     \n",
    "        plt.xlabel('Nodes') \n",
    "        plt.ylabel('ln(Steps)')\n",
    "        \n",
    "    if method==\"quasipolynomial\":\n",
    "        plt.title('Quasiplynomial behavior')     \n",
    "        plt.xlabel('ln(Nodes)*Nodes') \n",
    "        plt.ylabel('ln(Steps)')\n",
    "    \n",
    "    plt.legend(loc=\"upper left\")        \n",
    "    plt.show()\n",
    "\n",
    "    # Print table\n",
    "    print(\"Regression results:\\n\")\n",
    "    print(labels[0])\n",
    "    print(tabulate(list(zip(*[r_var, slopes1, intercepts1, r_values1])), headers=[r_var_label, 'slope', 'intercept', 'r_value'], floatfmt=\".3f\"))\n",
    "    print(labels[1])\n",
    "    print(tabulate(list(zip(*[r_var, slopes2, intercepts2, r_values2])), headers=[r_var_label, 'slope', 'intercept', 'r_value'], floatfmt=\".3f\"))\n",
    "    \n",
    "    return\n",
    "\n",
    "def PlotThreeRegressionResults(nodes1, steps_mean1, steps_sd1, nodes2, steps_mean2, steps_sd2, nodes3, steps_mean3, steps_sd3,\n",
    "                               with_errorbars, r_var, r_var_label, method, labels):\n",
    "    \n",
    "    # Create a new plot\n",
    "    plt.figure(np.random.randint(501, 1000))\n",
    "\n",
    "    # t runs over all columns of steps_mean\n",
    "    t=0\n",
    "    slopes1=[]\n",
    "    intercepts1=[]\n",
    "    r_values1=[]\n",
    "    p_values1=[]\n",
    "    std_errs1=[]    \n",
    "    # Convert X axis according to method\n",
    "    x1 = nodes1\n",
    "    if method==\"polynomial\":\n",
    "        x1 = np.log(x1.reshape(-1, 1))\n",
    "    if method == \"quasipolynomial\":\n",
    "        x1 = np.log(x1.reshape(-1, 1))*x1.reshape(-1, 1)\n",
    "    \n",
    "    # For the averae case, we have to reduce the number of vertices so that the have similar lengths\n",
    "    last_index = np.argmax(nodes1>np.max(nodes2))\n",
    "    if last_index == 0:\n",
    "        last_index = len(x1-1)\n",
    "    x1 = x1[:last_index]\n",
    "    steps_mean1 = steps_mean1[:last_index]\n",
    "    steps_sd1 = steps_sd1[:last_index]\n",
    "    \n",
    "    # Convert Y axis according to method\n",
    "    y1 = steps_mean1\n",
    "    if (method==\"polynomial\") or (method==\"exponential\") or (method==\"quasipolynomial\"):\n",
    "        y1 = np.log(y1)\n",
    "    plt.scatter(x1, y1, c = \"darkred\", alpha=0.5)\n",
    "    if with_errorbars:\n",
    "        if len(steps_sd1)>0:\n",
    "            y_sd1 = steps_sd1\n",
    "            plt.errorbar(x1,y1,yerr=y_sd1, linestyle=\"None\", c = \"darkred\", alpha=0.5)\n",
    "\n",
    "    # Linear regression\n",
    "    slope1, intercept1, r_value1, p_value1, std_err1 = stats.mstats.linregress(x1,y1)\n",
    "\n",
    "    # Store results\n",
    "    slopes1.append(slope1)\n",
    "    intercepts1.append(intercept1)\n",
    "    r_values1.append(r_value1)\n",
    "    p_values1.append(p_value1)\n",
    "    std_errs1.append(std_err1)\n",
    "\n",
    "    # Linear regression prediction\n",
    "    y_reg1 = intercept1 + slope1*x1\n",
    "    plt.plot(x1, y_reg1, label=labels[0], c = \"red\")\n",
    "        \n",
    "    # t runs over all columns of steps_mean\n",
    "    slopes2=[]\n",
    "    intercepts2=[]\n",
    "    r_values2=[]\n",
    "    p_values2=[]\n",
    "    std_errs2=[]   \n",
    "    \n",
    "    # X2 is smoothed, therefore no error bars\n",
    "    # Convert X axis according to method\n",
    "    x2 = nodes2\n",
    "    if method==\"polynomial\":\n",
    "        x2 = np.log(x2.reshape(-1, 1))\n",
    "    if method == \"quasipolynomial\":\n",
    "        x2 = np.log(x2.reshape(-1, 1))*x2.reshape(-1, 1)\n",
    "    \n",
    "    # Convert Y axis according to method\n",
    "    y2 = steps_mean2\n",
    "    if (method==\"polynomial\") or (method==\"exponential\") or (method==\"quasipolynomial\"):\n",
    "        y2 = np.log(y2)\n",
    "    plt.scatter(x2, y2, c = \"darkblue\", alpha=0.5)\n",
    "    if with_errorbars:\n",
    "        if len(steps_sd2)>0:\n",
    "            y_sd2 = steps_sd2\n",
    "            plt.errorbar(x2,y2,yerr=y_sd2, linestyle=\"None\", c = \"darkblue\", alpha=0.5)\n",
    "\n",
    "    # Linear regression\n",
    "    slope2, intercept2, r_value2, p_value2, std_err2 = stats.mstats.linregress(x2,y2)\n",
    "\n",
    "    # Store results\n",
    "    slopes2.append(slope2)\n",
    "    intercepts2.append(intercept2)\n",
    "    r_values2.append(r_value2)\n",
    "    p_values2.append(p_value2)\n",
    "    std_errs2.append(std_err2)\n",
    "\n",
    "    # Linear regression prediction\n",
    "    y_reg2 = intercept2 + slope2*x2\n",
    "    plt.plot(x2, y_reg2, label=labels[1], c = \"blue\")\n",
    "        \n",
    "    # t runs over all columns of steps_mean\n",
    "    slopes3=[]\n",
    "    intercepts3=[]\n",
    "    r_values3=[]\n",
    "    p_values3=[]\n",
    "    std_errs3=[]   \n",
    "    \n",
    "    # Convert X axis according to method\n",
    "    x3 = nodes3\n",
    "    if method==\"polynomial\":\n",
    "        x3 = np.log(x3.reshape(-1, 1))\n",
    "    if method == \"quasipolynomial\":\n",
    "        x3 = np.log(x3.reshape(-1, 1))*x3.reshape(-1, 1)\n",
    "    \n",
    "    # Convert Y axis according to method\n",
    "    y3 = steps_mean3\n",
    "    if (method==\"polynomial\") or (method==\"exponential\") or (method==\"quasipolynomial\"):\n",
    "        y3 = np.log(y3)\n",
    "    plt.scatter(x3, y3, c = \"darkgreen\", alpha=0.5)\n",
    "    if with_errorbars:\n",
    "        if len(steps_sd3)>0:\n",
    "            y_sd3 = steps_sd3\n",
    "            plt.errorbar(x3,y3,yerr=y_sd3, linestyle=\"None\", c = \"darkgreen\", alpha=0.5)\n",
    "\n",
    "    # Linear regression\n",
    "    slope3, intercept3, r_value3, p_value3, std_err3 = stats.mstats.linregress(x3,y3)\n",
    "\n",
    "    # Store results\n",
    "    slopes3.append(slope3)\n",
    "    intercepts3.append(intercept3)\n",
    "    r_values3.append(r_value3)\n",
    "    p_values3.append(p_value3)\n",
    "    std_errs3.append(std_err3)\n",
    "\n",
    "    # Linear regression prediction\n",
    "    y_reg3 = intercept3 + slope3*x3\n",
    "    plt.plot(x3, y_reg3, label=labels[2], c = \"green\")\n",
    "\n",
    "    if method==\"polynomial\":\n",
    "        plt.title('Polynomial behavior')     \n",
    "        plt.xlabel('ln(Nodes)') \n",
    "        plt.ylabel('ln(Steps)')\n",
    "    \n",
    "    if method==\"exponential\":\n",
    "        plt.title('Exponential behavior')     \n",
    "        plt.xlabel('Nodes') \n",
    "        plt.ylabel('ln(Steps)')\n",
    "        \n",
    "    if method==\"quasipolynomial\":\n",
    "        plt.title('Quasiplynomial behavior')     \n",
    "        plt.xlabel('ln(Nodes)*Nodes') \n",
    "        plt.ylabel('ln(Steps)')\n",
    "        \n",
    "    if method == \"lineal\":\n",
    "        plt.title('Ratios')     \n",
    "        plt.ylabel('local/global') \n",
    "        plt.xlabel('Nodes')\n",
    "    \n",
    "    plt.legend(loc=\"lower left\")        \n",
    "    plt.show()\n",
    "\n",
    "    # Print table\n",
    "    print(\"Regression results:\\n\")\n",
    "    print(tabulate(list(zip(*[labels[0], slopes1, intercepts1, r_values1])), headers=[r_var_label, 'slope', 'intercept', 'r_value'], floatfmt=\".3f\"))\n",
    "    print(tabulate(list(zip(*[labels[1], slopes2, intercepts2, r_values2])), headers=[r_var_label, 'slope', 'intercept', 'r_value'], floatfmt=\".3f\"))\n",
    "    print(tabulate(list(zip(*[labels[2], slopes3, intercepts3, r_values3])), headers=[r_var_label, 'slope', 'intercept', 'r_value'], floatfmt=\".3f\"))\n",
    "    \n",
    "    return\n",
    "\n",
    "def MultilinearRegression(X, Y, method):\n",
    "    import statsmodels.api as sm\n",
    "    from sklearn import linear_model\n",
    "    if method == \"log-log\":\n",
    "        X = np.log(X)\n",
    "        Y = np.log(Y)\n",
    "    X = sm.add_constant(X) # adding a constant\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    #predictions = model.predict(X) \n",
    "    print_model = model.summary()\n",
    "    print(print_model)\n",
    "    return model.params, model.rsquared\n",
    "\n",
    "def GreedyBestFlip(W, partition, n, k, z):\n",
    "    cut_costs = []\n",
    "    partitions_flip = []\n",
    "    # Permutate vertices so that we do not always start by the same one\n",
    "    order = np.random.permutation(range(n))\n",
    "    for i in order:\n",
    "        for j in range(1, k):            \n",
    "            new_partition = partition.copy()\n",
    "            new_partition[i] = (new_partition[i]+j)%k\n",
    "            partitions_flip.append(new_partition)\n",
    "            cut_costs.append(CutGainAfterFlip(W, partition, new_partition, n))\n",
    "      \n",
    "    # Convert the list to a numpy array\n",
    "    cut_costs = np.asarray(cut_costs)\n",
    "    if np.any(cut_costs[cut_costs>0]):\n",
    "        # New best partition was found\n",
    "        best_index = np.argmax(cut_costs)\n",
    "        best_partition = partitions_flip[best_index]\n",
    "        new_cut_cost = z + cut_costs[best_index]\n",
    "        return best_partition, new_cut_cost\n",
    "    else:\n",
    "        # We are in a local optimum\n",
    "        return partition, z\n",
    "    \n",
    "def RandomPositiveFlip(W, partition, n, k, z, seed = -1):\n",
    "    # Permutate vertices so that we do not always start by the same one\n",
    "    # Randomness\n",
    "    if seed == -1:\n",
    "        order = np.random.permutation(range(n))\n",
    "    else:\n",
    "        local_state = np.random.RandomState(seed)\n",
    "        order = local_state.permutation(range(n))\n",
    "    for i in order:\n",
    "        for j in range(1, k):            \n",
    "            new_partition = partition.copy()\n",
    "            new_partition[i] = (new_partition[i]+j)%k\n",
    "            new_z = CutGainAfterFlip(W, partition, new_partition, n)\n",
    "            if new_z > 0:\n",
    "                return new_partition, z + new_z\n",
    "      \n",
    "    return partition, z\n",
    "\n",
    "def WorstFlip(W, partition, n, k, z):\n",
    "    cut_costs = []\n",
    "    partitions_flip = []\n",
    "    # Permutate vertices so that we do not always start by the same one\n",
    "    order = np.random.permutation(range(n))\n",
    "    for i in order:\n",
    "        for j in range(1, k):            \n",
    "            new_partition = partition.copy()\n",
    "            new_partition[i] = (new_partition[i]+j)%k\n",
    "            partitions_flip.append(new_partition)\n",
    "            cut_costs.append(CutGainAfterFlip(W, partition, new_partition, n))\n",
    "      \n",
    "    # Convert the list to a numpy array\n",
    "    cut_costs = np.asarray(cut_costs)\n",
    "    \n",
    "    if np.any(cut_costs[cut_costs>0]):\n",
    "        # A better partition was found\n",
    "        min_val = min(c for c in cut_costs if c > 0)\n",
    "        worst_index = np.argwhere(cut_costs==min_val)[0][0]\n",
    "        worst_partition = partitions_flip[worst_index]\n",
    "        new_cut_cost = z + cut_costs[worst_index]\n",
    "        return worst_partition, new_cut_cost\n",
    "    else:\n",
    "        # We are in a local optimum\n",
    "        return partition, z\n",
    "\n",
    "def RunGridMaxCutAverageK(min_nodes, max_nodes, step_nodes, initial_partition_type, dropout, ks, min_weight, max_weight, iters_for_nk, heuristic, graph_type = \"complete\", storeCSV=False):\n",
    "\n",
    "    # Create nodes grid\n",
    "    # nodes = np.linspace(min_nodes, max_nodes, num=step_nodes, dtype=int)\n",
    "    nodes = np.logspace(np.log(min_nodes), np.log(max_nodes), num=step_nodes, base=np.exp(1))\n",
    "    # Remove decimal part\n",
    "    nodes = np.floor(nodes)\n",
    "    # Convert to integer\n",
    "    nodes = nodes.astype(int)\n",
    "\n",
    "    steps_mean = np.zeros((len(nodes), len(ks)))\n",
    "    steps_sd = np.zeros((len(nodes), len(ks)))\n",
    "    \n",
    "    # Save nodes\n",
    "    if storeCSV:\n",
    "        NumpyToCsv(nodes, \"nodes\")\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for ni in nodes:\n",
    "        weights_size = int(ni*(ni-1)/2)\n",
    "        for ki in ks:\n",
    "            steps = np.zeros(iters_for_nk)\n",
    "            for it in range(iters_for_nk):\n",
    "                # Create graph and initial partition\n",
    "                W_k_it = InitializeFlatGraph(weights_size, min_weight, max_weight, dropout, graph_type=graph_type)\n",
    "                W_k_it = SymmetricMatrix(W_k_it)\n",
    "                initial_partition = GetInitialPartition(ni, ki, initial_partition_type)\n",
    "                # Get initial cost value\n",
    "                initial_z = CutCost(W_k_it, initial_partition, ni, ki)\n",
    "                # Get next local maximum\n",
    "                partition, z, elapsed_time, n_steps = SolveMaxCut(W_k_it, ni, ki, initial_z, initial_partition, heuristic)\n",
    "                # Save results for each iteration\n",
    "                steps[it]=n_steps\n",
    "             \n",
    "            # Save results for a i,j combination    \n",
    "            steps_mean[i,j] = np.mean(steps)\n",
    "            steps_sd[i,j] = np.std(steps)/np.sqrt(iters_for_nk)\n",
    "            if storeCSV:\n",
    "                DeleteTempResults(\"average_complexities.csv\")\n",
    "                NumpyToCsv(steps_mean, \"average_complexities\")\n",
    "                DeleteTempResults(\"average_complexities_sd.csv\")\n",
    "                NumpyToCsv(steps_sd, \"average_complexities_sd\")\n",
    "            j = j + 1\n",
    "        j = 0\n",
    "        i = i + 1\n",
    "    return steps_mean, steps_sd, nodes\n",
    "\n",
    "def FindWorstInstance(n, initial_partition_type, dropout, k, min_weight, max_weight, iters_for_nk, heuristic, storeCSV=False):\n",
    "    steps = np.zeros(iters_for_nk)   \n",
    "    weights_size = int(n*(n-1)/2)\n",
    "    max_value = 0\n",
    "    for it in range(iters_for_nk):\n",
    "        # Create graph and initial partition\n",
    "        W_k_it = InitializeFlatGraph(weights_size, min_weight, max_weight, dropout)\n",
    "        W_k_it = SymmetricMatrix(W_k_it)\n",
    "        initial_partition = GetInitialPartition(n, k, initial_partition_type)\n",
    "        # Get initial cost value\n",
    "        initial_z = CutCost(W_k_it, initial_partition, n, k)\n",
    "        # Get next local maximum\n",
    "        partition, z, elapsed_time, n_steps = SolveMaxCut(W_k_it, n, k, initial_z, initial_partition, heuristic)\n",
    "        # Save results for each iteration\n",
    "        steps[it]=n_steps            \n",
    "        if n_steps>max_value:\n",
    "            max_value = n_steps\n",
    "            worst_instance = W_k_it\n",
    "            \n",
    "    if storeCSV:\n",
    "        DeleteTempResults(\"n_steps.csv\")\n",
    "        NumpyToCsv(steps, \"n_steps\")\n",
    "        DeleteTempResults(\"worst_instance.csv\")\n",
    "        NumpyToCsv(worst_instance, \"worst_instance\")\n",
    "    return n, steps\n",
    "\n",
    "def RunGridMaxCutAverageDropout(min_nodes, max_nodes, step_nodes, initial_partition_type, dropouts, k, min_weight, max_weight, iters_for_nk, heuristic):\n",
    "\n",
    "    # Create nodes grid\n",
    "    # nodes = np.linspace(min_nodes, max_nodes, num=step_nodes, dtype=int)\n",
    "    nodes = np.logspace(np.log(min_nodes), np.log(max_nodes), num=step_nodes, base=np.exp(1))\n",
    "    # Remove decimal part\n",
    "    nodes = np.floor(nodes)\n",
    "    # Convert to integer\n",
    "    nodes = nodes.astype(int)\n",
    "\n",
    "    steps_mean = np.zeros((len(nodes), len(dropouts)))\n",
    "    steps_sd = np.zeros((len(nodes), len(dropouts)))\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for ni in nodes:\n",
    "        for d in dropouts:\n",
    "            steps = np.zeros(iters_for_nk)\n",
    "            for it in range(iters_for_nk):\n",
    "                # Create graph and initial partition\n",
    "                W = InitializeGraph(ni, min_weight, max_weight, d)\n",
    "                initial_partition = GetInitialPartition(ni, k, initial_partition_type)\n",
    "                # Get initial cost value\n",
    "                initial_z = CutCost(W, initial_partition, ni, k)\n",
    "                # Get next local maximum\n",
    "                partition, z, elapsed_time, n_steps = SolveMaxCut(W, ni, k, initial_z, initial_partition, heuristic)\n",
    "                # Save results for each iteration\n",
    "                steps[it]=n_steps\n",
    "                \n",
    "            # Save results for a i,j combination    \n",
    "            steps_mean[i,j] = np.mean(steps)\n",
    "            steps_sd[i,j] = np.std(steps)/np.sqrt(iters_for_nk)\n",
    "            j = j + 1\n",
    "        j = 0\n",
    "        i = i + 1\n",
    "    return steps_mean, steps_sd, nodes\n",
    "\n",
    "def RunGridMaxCutAverageDegrees(min_nodes, max_nodes, step_nodes, initial_partition_type, degrees, k, min_weight, max_weight, iters_for_nk, heuristic):\n",
    "\n",
    "    # Create nodes grid\n",
    "    # nodes = np.linspace(min_nodes, max_nodes, num=step_nodes, dtype=int)\n",
    "    nodes = np.logspace(np.log(min_nodes), np.log(max_nodes), num=step_nodes, base=np.exp(1))\n",
    "    # Remove decimal part\n",
    "    nodes = np.floor(nodes)\n",
    "    # Convert to integer\n",
    "    nodes = nodes.astype(int)\n",
    "\n",
    "    steps_mean = np.zeros((len(nodes), len(dropouts)))\n",
    "    steps_sd = np.zeros((len(nodes), len(dropouts)))\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for ni in nodes:\n",
    "        for d in degrees:\n",
    "            steps = np.zeros(iters_for_nk)\n",
    "            for it in range(iters_for_nk):\n",
    "                # Create graph and initial partition\n",
    "                W = InitializeGraph(ni, min_weight, max_weight, d)\n",
    "                initial_partition = GetInitialPartition(ni, k, initial_partition_type)\n",
    "                # Get initial cost value\n",
    "                initial_z = CutCost(W, initial_partition, ni, k)\n",
    "                # Get next local maximum\n",
    "                partition, z, elapsed_time, n_steps = SolveMaxCut(W, ni, k, initial_z, initial_partition, heuristic)\n",
    "                # Save results for each iteration\n",
    "                steps[it]=n_steps\n",
    "                \n",
    "            # Save results for a i,j combination    \n",
    "            steps_mean[i,j] = np.mean(steps)\n",
    "            steps_sd[i,j] = np.std(steps)/np.sqrt(iters_for_nk)\n",
    "            j = j + 1\n",
    "        j = 0\n",
    "        i = i + 1\n",
    "    return steps_mean, steps_sd, nodes\n",
    "\n",
    "def RunGridMaxCutAverageHeuristics(min_nodes, max_nodes, step_nodes, initial_partition_type, dropout, k, min_weight, max_weight, iters_for_nk, heuristics):\n",
    "\n",
    "    # Create nodes grid\n",
    "    # nodes = np.linspace(min_nodes, max_nodes, num=step_nodes, dtype=int)\n",
    "    nodes = np.logspace(np.log(min_nodes), np.log(max_nodes), num=step_nodes, base=np.exp(1))\n",
    "    # Remove decimal part\n",
    "    nodes = np.floor(nodes)\n",
    "    # Convert to integer\n",
    "    nodes = nodes.astype(int)\n",
    "\n",
    "    steps_mean = np.zeros((len(nodes), len(heuristics)))\n",
    "    steps_sd = np.zeros((len(nodes), len(heuristics)))\n",
    "    \n",
    "    max_cut_mean = np.zeros((len(nodes), len(heuristics)))\n",
    "    max_cut_sd = np.zeros((len(nodes), len(heuristics)))\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for ni in nodes:\n",
    "        for h in heuristics:\n",
    "            steps = np.zeros(iters_for_nk)\n",
    "            max_cuts = np.zeros(iters_for_nk)\n",
    "            for it in range(iters_for_nk):\n",
    "                # Create graph and initial partition\n",
    "                W = InitializeGraph(ni, min_weight, max_weight, dropout)\n",
    "                initial_partition = GetInitialPartition(ni, k, initial_partition_type)\n",
    "                # Get initial cost value\n",
    "                initial_z = CutCost(W, initial_partition, ni, k)\n",
    "                # Select method\n",
    "                partition, z, elapsed_time, n_steps = SolveMaxCut(W, ni, k, initial_z, initial_partition, h)\n",
    "                # Save results for each iteration\n",
    "                steps[it]=n_steps\n",
    "                max_cuts[it] = z\n",
    "                \n",
    "            # Save results for a i,j combination    \n",
    "            steps_mean[i,j] = np.mean(steps)\n",
    "            steps_sd[i,j] = np.std(steps)/np.sqrt(iters_for_nk)\n",
    "            max_cut_mean[i,j] = np.mean(max_cuts)\n",
    "            max_cut_sd[i,j] = np.std(max_cuts)/np.sqrt(iters_for_nk)\n",
    "            j = j + 1\n",
    "        j = 0\n",
    "        i = i + 1\n",
    "    return steps_mean, steps_sd, max_cut_mean, max_cut_sd, nodes\n",
    "\n",
    "def RunGridMaxCutAverageIntercalations(min_nodes, max_nodes, step_nodes, initial_partition_type, dropout, k, min_weight, max_weight, iters_for_nk, heuristic, intercalations, storeCSV=False):\n",
    "\n",
    "    # Create nodes grid\n",
    "    # nodes = np.linspace(min_nodes, max_nodes, num=step_nodes, dtype=int)\n",
    "    nodes = np.logspace(np.log(min_nodes), np.log(max_nodes), num=step_nodes, base=np.exp(1))\n",
    "    # Remove decimal part\n",
    "    nodes = np.floor(nodes)\n",
    "    # Convert to integer\n",
    "    nodes = nodes.astype(int)\n",
    "\n",
    "    steps_mean = np.zeros((len(nodes), len(intercalations)))\n",
    "    steps_sd = np.zeros((len(nodes), len(intercalations)))\n",
    "    \n",
    "    # Save nodes\n",
    "    if storeCSV:\n",
    "        NumpyToCsv(nodes, \"nodes\")\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for ni in nodes:\n",
    "        weights_size = int(ni*(ni-1)/2)\n",
    "        for intercalation in intercalations:\n",
    "            real_intercalation = np.floor(intercalation*ni).astype(int)\n",
    "            steps = np.zeros(iters_for_nk)\n",
    "            for it in range(iters_for_nk):\n",
    "                # Create graph and initial partition\n",
    "                W_k_it = InitializeFlatGraph(weights_size, min_weight, max_weight, dropout, None, \"intercalate\", real_intercalation)\n",
    "                W_k_it = SymmetricMatrix(W_k_it)\n",
    "                initial_partition = GetInitialPartition(ni, k, initial_partition_type)\n",
    "                # Get initial cost value\n",
    "                initial_z = CutCost(W_k_it, initial_partition, ni, k)\n",
    "                # Get next local maximum\n",
    "                partition, z, elapsed_time, n_steps = SolveMaxCut(W_k_it, ni, k, initial_z, initial_partition, heuristic)\n",
    "                # Save results for each iteration\n",
    "                steps[it]=n_steps\n",
    "             \n",
    "            # Save results for a i,j combination    \n",
    "            steps_mean[i,j] = np.mean(steps)\n",
    "            steps_sd[i,j] = np.std(steps)/np.sqrt(iters_for_nk)\n",
    "            if storeCSV:\n",
    "                DeleteTempResults(\"average_complexities.csv\")\n",
    "                NumpyToCsv(steps_mean, \"average_complexities\")\n",
    "                DeleteTempResults(\"average_complexities_sd.csv\")\n",
    "                NumpyToCsv(steps_sd, \"average_complexities_sd\")\n",
    "            j = j + 1\n",
    "        j = 0\n",
    "        i = i + 1\n",
    "    return  nodes, steps_mean, steps_sd,\n",
    "\n",
    "#GLOBAL\n",
    "def SolveGlobalAndLocalMaxCut(nodes, iters, min_weight, max_weight, heuristics, k, initial_partition_type, dropout, storeCSV=False):\n",
    "    # Average value for each node (global)\n",
    "    global_average_value = np.zeros((len(nodes), 1))\n",
    "    global_average_value_sd = np.zeros((len(nodes), 1))\n",
    "    \n",
    "    # Average value for each node (local) and heuristic\n",
    "    local_average_value = np.zeros((len(nodes), len(heuristics)))\n",
    "    local_average_value_sd = np.zeros((len(nodes), len(heuristics)))\n",
    "    \n",
    "    # Avg(local/global) for each node and heuristic\n",
    "    average_ratios = np.zeros((len(nodes), len(heuristics)))\n",
    "    average_ratios_sd = np.zeros((len(nodes), len(heuristics)))\n",
    "    \n",
    "    # Save nodes\n",
    "    if storeCSV:\n",
    "        NumpyToCsv(nodes, \"nodes\")\n",
    "    # Save lengths\n",
    "    nodes_length = len(nodes)\n",
    "    heuristics_length = len(heuristics)\n",
    "    \n",
    "    # Start loop\n",
    "    for i in range(nodes_length):\n",
    "        # Get current node\n",
    "        n = int(nodes[i])\n",
    "        \n",
    "        # Get initial partition\n",
    "        initial_partition = GetInitialPartition(n, k, initial_partition_type)\n",
    "        \n",
    "        # Create variable to store results for each iteration\n",
    "        global_value_iters = np.zeros((iters, 1))\n",
    "        local_value_iters = np.zeros((iters, len(heuristics)))\n",
    "        ratios_iters = np.zeros((iters, len(heuristics)))\n",
    "        \n",
    "        # Start loop for each iteration\n",
    "        for it in range(iters):\n",
    "            # Initialize graph\n",
    "            W = InitializeGraph(n, min_weight, max_weight, dropout)\n",
    "            # Global result\n",
    "            _p, global_value_iter = GurobiSolveMaxCut(W, n)\n",
    "            global_value_iters[it] = global_value_iter\n",
    "            # Local result for each heuristic\n",
    "            initial_cut = CutCost(W, initial_partition, n, k)\n",
    "            #print(\"Global value\", global_value_iter)\n",
    "            for h in range(heuristics_length):\n",
    "                heuristic = heuristics[h]\n",
    "                _p, local_value_iter_heuristic, _t, _it = SolveMaxCut(W, n, k, initial_cut, initial_partition, heuristic)\n",
    "                local_value_iters[it,h] = local_value_iter_heuristic\n",
    "                #print(\"Heuristic\", heuristic, local_value_iter_heuristic)\n",
    "                if global_value_iter == 0:\n",
    "                    ratios_iters[it,h] = 1\n",
    "                else:\n",
    "                    ratios_iters[it,h] = local_value_iter_heuristic/global_value_iter                    \n",
    "                    #ratios_iters[it,h] = abs(local_value_iter_heuristic-global_value_iter)/global_value_iter\n",
    "\n",
    "                print(\"Iter \", it, \", ratio(\", heuristics[h], \"):\", ratios_iters[it,h])\n",
    "              \n",
    "        # Get the average values and append them\n",
    "        global_average_value[i] = np.mean(global_value_iters)\n",
    "        local_average_value[i] = np.mean(local_value_iters, axis = 0)\n",
    "        average_ratios[i] = np.mean(ratios_iters, axis = 0)\n",
    "        \n",
    "        # Get the sd and append them\n",
    "        global_average_value_sd[i] = np.std(global_value_iters)\n",
    "        local_average_value_sd[i] = np.std(local_value_iters, axis = 0)\n",
    "        average_ratios_sd[i] = np.std(ratios_iters, axis = 0)\n",
    "        \n",
    "        # Store\n",
    "        if storeCSV:\n",
    "            DeleteTempResults(\"global_average_value.csv\")\n",
    "            NumpyToCsv(global_average_value, \"global_average_value\")\n",
    "            DeleteTempResults(\"local_average_value.csv\")\n",
    "            NumpyToCsv(local_average_value, \"local_average_value\")\n",
    "            DeleteTempResults(\"average_ratios.csv\")\n",
    "            NumpyToCsv(average_ratios, \"average_ratios\")\n",
    "            DeleteTempResults(\"global_average_value.csv\")\n",
    "            NumpyToCsv(global_average_value_sd, \"global_average_value_sd\")\n",
    "            DeleteTempResults(\"local_average_value_sd.csv\")\n",
    "            NumpyToCsv(local_average_value_sd, \"local_average_value_sd\")\n",
    "            DeleteTempResults(\"average_ratios_sd.csv\")\n",
    "            NumpyToCsv(average_ratios_sd, \"average_ratios_sd\")\n",
    "   \n",
    "    return global_average_value, local_average_value, average_ratios, global_average_value_sd, local_average_value_sd, average_ratios_sd\n",
    "\n",
    "nodes = np.linspace(10, 10, num=1)\n",
    "# Remove decimal part\n",
    "nodes = np.floor(nodes)\n",
    "# Convert to integer\n",
    "nodes = nodes.astype(int)\n",
    "iters = 100\n",
    "min_weight = 0\n",
    "max_weight = 1\n",
    "heuristics = [\"GBF\", \"RPF\", \"WF\"]\n",
    "k = 2\n",
    "initial_partition = \"0\"\n",
    "dropout = 0\n",
    "\n",
    "global_average_value, local_average_value, average_ratios, global_average_value_sd, local_average_value_sd, average_ratios_sd = SolveGlobalAndLocalMaxCut(nodes, iters, min_weight, max_weight, heuristics, k, initial_partition, dropout, storeCSV=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
